services:
  ollama:
    image: ollama/ollama:0.6.0
    container_name: ollama
    restart: unless-stopped
    gpus:
      - driver: nvidia
        count: 1
    environment:
      - OLLAMA_ORIGINS=*
    ports:
      - 11434:11434
    volumes:
      - ollama-data:/root/.ollama

  litellm:
    image: ghcr.io/berriai/litellm:main-v1.61.3
    container_name: litellm
    restart: unless-stopped
    environment:
      - ANTHROPIC_API_KEY=### YOUR ANTHROPIC API KEY ###
      - AZURE_API_KEY=### YOUR AZURE API KEY HERE ###
      - AZURE_API_BASE=### AZURE API ENDPOINT URL ###
      - AZURE_API_VERSION=### AZURE API VERSION ###
      - GEMINI_API_KEY=### GEMINI API KEY HERE ###
    ports:
      - 4000:4000
    volumes:
      - $PWD/litellm-config.yaml:/app/config.yaml
    command: ["--config", "/app/config.yaml"]

  open-webui:
    image: ghcr.io/open-webui/open-webui:v0.5.20
    container_name: open-webui
    restart: unless-stopped
    ports:
      - 6173:8080
    volumes:
      - open-webui-data:/app/backend/data
    depends_on:
      - ollama
    environment:
      - 'OLLAMA_BASE_URL=http://ollama:11434'
      - 'WEBUI_SECRET_KEY='
    extra_hosts:
      - host.docker.internal:host-gateway

volumes:
  ollama-data:
  open-webui-data:
